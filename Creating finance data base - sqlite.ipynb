{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crreating finance database for BSE sensex and DOW jonse\n",
    "# 1. Importing necessary modules\n",
    "import fix_yahoo_finance as yf\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "# 2. Links to extract data from \n",
    "wiki = 'https://en.wikipedia.org/wiki/'\n",
    "tickersSensex = pd.read_html(wiki + 'BSE_SENSEX')[1]['Symbol'].to_list() \n",
    "tickersDOW = pd.read_html(wiki + 'Dow_Jones_Industrial_Average')[1]['Symbol'].to_list()\n",
    "\n",
    "def getdata(tickers):\n",
    "    data = []\n",
    "    for ticker in tickers:\n",
    "        data.append(yf.download(ticker, start = '2021-12-01').reset_index())\n",
    "    return data\n",
    "\n",
    "def creaatengine(name):\n",
    "    engine = sqlalchemy.create_engine('sqlite:///'+ name)\n",
    "    return engine\n",
    "\n",
    "indiaengine, USengine = creaatengine(\"India\"), creaatengine('USA')\n",
    "\n",
    "def TOSQL(frames, symbols, engine):\n",
    "    for frame, symbol in zip(frames, symbols):\n",
    "        frame.to_sql(symbol, engine, index = False)\n",
    "    print('Successfully imported data')\n",
    "\n",
    "TOSQL(india, tickersSensex, indiaengine)    \n",
    "TOSQL(US, tickersDOW, USengine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importing necessary modules\n",
    "# import fix_yahoo_finance as yf\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Links to extract data from \n",
    "wiki = 'https://en.wikipedia.org/wiki/'\n",
    "\n",
    "# Fetching top 30 stocks from BSE\n",
    "tickersSensex = pd.read_html(wiki + 'BSE_SENSEX')[1]['Symbol'].to_list()\n",
    "\n",
    "# Fetching top 30 stocks from dow jonse\n",
    "tickersDOW = pd.read_html(wiki + 'Dow_Jones_Industrial_Average')[1]['Symbol'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# 3. Extracting information about top 30 stocks in india as well as USA\n",
    "def getdata(tickers, date): # tickers = list of all scripts , date = start date to download\n",
    "    data = []\n",
    "    for symbol in tickers:\n",
    "        data.append(yf.download(symbol, start = date)) # downloading data for each script\n",
    "    return data # list of data frame of all script in ticker\n",
    "\n",
    "India, US = getdata(tickersSensex, date='2022-01-01'), getdata(tickersDOW, date='2022-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Creating data base of desire name\n",
    "def createengine(name): # name = name of database \n",
    "    engine = sqlalchemy.create_engine('sqlite:///' + name)\n",
    "    return engine\n",
    "indianengine, usaengine = createengine('India'), createengine('USA')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Populating indianengine and usaengine\n",
    "def TOSQL(frames, symbols, engine):\n",
    "    for frame, symbol in zip(frames, symbols):\n",
    "        frame.to_sql(symbol, engine, index = False)\n",
    "    print('Successfully imported data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported data\n",
      "Successfully imported data\n"
     ]
    }
   ],
   "source": [
    "TOSQL(India, tickersSensex,indianengine)\n",
    "TOSQL(US, tickersDOW,usaengine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
